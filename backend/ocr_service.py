#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCRæœåŠ¡ - ä»ocr_deduplicate.pyæ”¹é€ è€Œæ¥
"""

import re
import subprocess
import shutil
import hashlib
import json
import concurrent.futures
from pathlib import Path
from collections import defaultdict
from datetime import datetime

class OCRService:
    def __init__(self, source_folder, result_folder):
        self.source_folder = Path(source_folder)
        self.result_folder = Path(result_folder)
        self.deduped_folder = self.result_folder / 'deduped'
        self.deduped_folder.mkdir(exist_ok=True)
        
        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
        self.cache_file = self.result_folder / 'ocr_cache.json'
        self.cache = self.load_cache()
    
    def get_file_fingerprint(self, file_path):
        """ç”Ÿæˆæ–‡ä»¶æŒ‡çº¹ï¼ˆè·¯å¾„+å¤§å°+ä¿®æ”¹æ—¶é—´ï¼‰"""
        try:
            stat = file_path.stat()
            relative_path = str(file_path.relative_to(self.source_folder))
            fingerprint = f"{relative_path}:{stat.st_size}:{stat.st_mtime}"
            return hashlib.md5(fingerprint.encode()).hexdigest()
        except:
            return None
    
    def load_cache(self):
        """åŠ è½½OCRç¼“å­˜"""
        if not self.cache_file.exists():
            return {}
        
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)
                print(f"âœ“ åŠ è½½ç¼“å­˜: {len(cache)} æ¡è®°å½•")
                return cache
        except Exception as e:
            print(f"âœ— åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return {}
    
    def save_cache(self):
        """ä¿å­˜OCRç¼“å­˜"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
                print(f"âœ“ ç¼“å­˜å·²ä¿å­˜: {len(self.cache)} æ¡è®°å½•")
        except Exception as e:
            print(f"âœ— ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def is_cached(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¼“å­˜"""
        fingerprint = self.get_file_fingerprint(file_path)
        if not fingerprint:
            return False
        
        if fingerprint in self.cache:
            cached_data = self.cache[fingerprint]
            # éªŒè¯ç¼“å­˜æ•°æ®çš„å®Œæ•´æ€§
            if all(key in cached_data for key in ['order_number', 'amount', 'folder', 'relative_path', 'ocr_time']):
                return True
        
        return False
    
    def get_cached_result(self, file_path):
        """è·å–ç¼“å­˜çš„è¯†åˆ«ç»“æœ"""
        fingerprint = self.get_file_fingerprint(file_path)
        if fingerprint and fingerprint in self.cache:
            return self.cache[fingerprint]
        return None
    
    def cache_result(self, file_path, order_number, amount, folder, relative_path):
        """ç¼“å­˜è¯†åˆ«ç»“æœ"""
        fingerprint = self.get_file_fingerprint(file_path)
        if fingerprint:
            self.cache[fingerprint] = {
                'order_number': order_number,
                'amount': amount,
                'folder': folder,
                'relative_path': relative_path,
                'ocr_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def get_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            print(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: {file_path} - {e}")
            return None
    
    def ocr_image(self, image_path):
        """ä½¿ç”¨tesseractè¯†åˆ«å›¾ç‰‡æ–‡å­—"""
        try:
            result = subprocess.run(
                ['tesseract', str(image_path), 'stdout', '-l', 'chi_sim+eng'],
                capture_output=True,
                text=True,
                timeout=15
            )
            return result.stdout
        except:
            # å¦‚æœä¸­æ–‡å¤±è´¥ï¼Œå°è¯•ä»…è‹±æ–‡
            try:
                result = subprocess.run(
                    ['tesseract', str(image_path), 'stdout'],
                    capture_output=True,
                    text=True,
                    timeout=15
                )
                return result.stdout
            except Exception as e:
                return ""
    
    def ocr_image_deep(self, image_path):
        """æ·±åº¦OCR - ä½¿ç”¨å¤šç§PSMæ¨¡å¼"""
        texts = []
        
        # å°è¯•ä¸åŒçš„PSMæ¨¡å¼
        for psm in ['6', '11', '12']:
            try:
                result = subprocess.run(
                    ['tesseract', str(image_path), 'stdout', '--psm', psm],
                    capture_output=True,
                    text=True,
                    timeout=15
                )
                texts.append(result.stdout)
            except:
                pass
        
        return "\n".join(texts)
    
    def extract_order_number(self, text):
        """ä»OCRæ–‡æœ¬ä¸­æå–è®¢å•ç¼–å· - æ”¯æŒè·¨è¡Œè¯†åˆ«"""
        # å…ˆå°è¯•å¸¸è§„åŒ¹é…ï¼ˆå•è¡Œå®Œæ•´è®¢å•å·ï¼‰
        patterns = [
            r'è®¢å•å·[:ï¼š\s]*([0-9A-Za-z]{18,32})',
            r'å•å·[:ï¼š\s]*([0-9A-Za-z]{18,32})',
            r'è®¢å•ç¼–å·[:ï¼š\s]*([0-9A-Za-z]{18,32})',
            r'å•†æˆ·è®¢å•å·[:ï¼š\s]*([0-9A-Za-z]{18,32})',
            r'äº¤æ˜“å•å·[:ï¼š\s]*([0-9A-Za-z]{18,32})',
            r'\b([0-9]{20,32})\b',
            r'\b([0-9A-Za-z]{24,32})\b',
        ]
        
        # é¦–å…ˆå°è¯•å¸¸è§„å•è¡ŒåŒ¹é…
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                order_num = matches[0].strip()
                # è¿‡æ»¤æ‰ä¸€äº›å¸¸è§çš„è¯¯è¯†åˆ«ï¼ˆå¦‚æ—¥æœŸã€æ—¶é—´ç­‰ï¼‰
                if len(order_num) >= 18 and not order_num.startswith('2025') and not order_num.startswith('2024'):
                    return order_num
        
        # å¦‚æœå•è¡ŒåŒ¹é…å¤±è´¥ï¼Œå°è¯•è·¨è¡Œæ‹¼æ¥
        lines = text.split('\n')
        
        for i, line in enumerate(lines):
            # æŸ¥æ‰¾åŒ…å«"è®¢å•å·"ç­‰å…³é”®è¯çš„è¡Œ
            if re.search(r'è®¢å•å·|å•å·|è®¢å•ç¼–å·|å•†æˆ·è®¢å•å·|äº¤æ˜“å•å·', line, re.IGNORECASE):
                # æå–å½“å‰è¡Œçš„æ•°å­—å­—æ¯éƒ¨åˆ†
                current_line_numbers = re.findall(r'[:ï¼š\s]*([0-9A-Za-z]+)', line)
                
                # å¦‚æœå½“å‰è¡Œæœ‰æ•°å­—ï¼Œä¸”é•¿åº¦ä¸å¤Ÿï¼ˆå¯èƒ½è¢«æˆªæ–­ï¼‰
                for num in current_line_numbers:
                    if len(num) >= 10 and len(num) < 32:
                        # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æœ‰ç»§ç»­çš„æ•°å­—
                        if i + 1 < len(lines):
                            next_line = lines[i + 1].strip()
                            next_numbers = re.findall(r'^([0-9A-Za-z]+)', next_line)
                            
                            if next_numbers:
                                # æ‹¼æ¥ä¸¤è¡Œçš„è®¢å•å·
                                combined = num + next_numbers[0]
                                # éªŒè¯æ‹¼æ¥åçš„é•¿åº¦æ˜¯å¦åˆç†
                                if 18 <= len(combined) <= 32:
                                    if not (combined.startswith('2025') or combined.startswith('2024') or combined.startswith('2023')):
                                        return combined
        
        # æŸ¥æ‰¾å¯èƒ½è·¨è¡Œçš„é•¿æ•°å­—ä¸²
        for i in range(len(lines) - 1):
            line = lines[i].strip()
            next_line = lines[i + 1].strip()
            
            line_no_space = ''.join(re.findall(r'[0-9A-Za-z]+', line))
            
            end_match = re.search(r'([0-9A-Za-z]{10,})$', line_no_space)
            if end_match:
                end_part = end_match.group(1)
                
                start_match = re.search(r'^([0-9A-Za-z]{4,})', next_line)
                if start_match:
                    start_part = start_match.group(1)
                    
                    combined = end_part + start_part
                    
                    if 18 <= len(combined) <= 32:
                        digit_ratio = sum(c.isdigit() for c in combined) / len(combined)
                        if digit_ratio >= 0.7:
                            if combined.startswith('4200') or combined.startswith('1000') or combined.startswith('372'):
                                return combined
                            elif not (combined.startswith('2025') or combined.startswith('2024') or combined.startswith('2023')):
                                return combined
        
        return None
    
    def extract_amount(self, text):
        """ä»OCRæ–‡æœ¬ä¸­æå–é‡‘é¢"""
        patterns = [
            r'-(\d+\.\d{2})',
            r'Â¥(\d+\.\d{2})',
            r'ï¿¥(\d+\.\d{2})',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            if matches:
                return float(matches[0])
        
        all_numbers = re.findall(r'\b(\d+\.\d{2})\b', text)
        if all_numbers:
            valid_amounts = [float(num) for num in all_numbers if 0.01 <= float(num) < 100000]
            if valid_amounts:
                return max(valid_amounts)
        
        return None
    
    def process_single_image(self, image_file):
        """å¤„ç†å•ä¸ªå›¾ç‰‡ï¼ˆç”¨äºå¹¶å‘å¤„ç†ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤æ–‡ä»¶
            file_hash = self.get_file_hash(image_file)
            is_duplicate = file_hash in self.duplicate_files
            
            # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä¿æŒæ–‡ä»¶å¤¹ç»“æ„
            try:
                relative_path = image_file.relative_to(self.source_folder)
                folder_path = str(relative_path.parent) if relative_path.parent != Path('.') else 'æ ¹ç›®å½•'
                display_name = str(relative_path)
            except:
                folder_path = image_file.parent.name
                display_name = image_file.name
            
            if is_duplicate:
                return {'type': 'duplicate', 'file': image_file, 'display_name': display_name}
            
            # æ£€æŸ¥ç¼“å­˜
            if self.is_cached(image_file):
                cached_result = self.get_cached_result(image_file)
                if cached_result:
                    print(f"âœ“ ä½¿ç”¨ç¼“å­˜: {display_name}")
                    return {
                        'type': 'cached',
                        'file': image_file,
                        'order_number': cached_result['order_number'],
                        'amount': cached_result['amount'],
                        'folder': cached_result['folder'],
                        'relative_path': cached_result['relative_path'],
                        'display_name': display_name
                    }
            
            # è¿›è¡ŒOCRè¯†åˆ«
            print(f"ğŸ” OCRè¯†åˆ«: {display_name}")
            
            # ç¬¬ä¸€è½®ï¼šå¸¸è§„OCR
            ocr_text = self.ocr_image(image_file)
            
            order_number = self.extract_order_number(ocr_text)
            amount = self.extract_amount(ocr_text)
            
            # å¦‚æœå¸¸è§„OCRå¤±è´¥ï¼Œå°è¯•æ·±åº¦OCR
            if order_number is None or amount is None:
                print(f"  â†’ å¸¸è§„è¯†åˆ«å¤±è´¥ï¼Œå°è¯•æ·±åº¦è¯†åˆ«...")
                deep_text = self.ocr_image_deep(image_file)
                
                combined_text = ocr_text + "\n" + deep_text
                
                if order_number is None:
                    order_number = self.extract_order_number(combined_text)
                if amount is None:
                    amount = self.extract_amount(combined_text)
            
            if order_number and amount:
                # ç¼“å­˜ç»“æœ
                self.cache_result(image_file, order_number, amount, folder_path, display_name)
                
                print(f"  âœ“ è®¢å•å·: {order_number} (é•¿åº¦:{len(order_number)}), é‡‘é¢: Â¥{amount:.2f}")
                return {
                    'type': 'success',
                    'file': image_file,
                    'order_number': order_number,
                    'amount': amount,
                    'folder': folder_path,
                    'relative_path': display_name,
                    'display_name': display_name
                }
            else:
                print(f"  âœ— è¯†åˆ«å¤±è´¥ - è®¢å•å·: {order_number or 'æ— '}, é‡‘é¢: {amount or 'æ— '}")
                return {'type': 'failed', 'file': image_file, 'display_name': display_name}
                
        except Exception as e:
            print(f"  âœ— å¤„ç†å¼‚å¸¸: {image_file.name} - {e}")
            return {'type': 'error', 'file': image_file, 'error': str(e)}
    
    def find_all_images(self):
        """é€’å½’æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡ï¼Œä¿æŒæ–‡ä»¶å¤¹ç»“æ„"""
        image_files = []
        
        for ext in ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG', '*.png', '*.PNG']:
            image_files.extend(self.source_folder.rglob(ext))
        
        return sorted(image_files)
    
    def process_images(self, image_files):
        """å¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼Œæå–è®¢å•å·å’Œé‡‘é¢ï¼ŒåŒæ—¶æ£€æµ‹é‡å¤ï¼ˆæ”¯æŒç¼“å­˜å’Œå¹¶å‘ï¼‰"""
        results = []
        failed_files = []
        duplicate_files = {}  # {hash: [file1, file2, ...]}
        
        total = len(image_files)
        
        # ç¬¬ä¸€æ­¥ï¼šè®¡ç®—æ‰€æœ‰æ–‡ä»¶çš„å“ˆå¸Œå€¼ï¼Œæ£€æµ‹é‡å¤
        print("æ­£åœ¨æ£€æµ‹é‡å¤æ–‡ä»¶...")
        file_hashes = {}
        for image_file in image_files:
            file_hash = self.get_file_hash(image_file)
            if file_hash:
                if file_hash in file_hashes:
                    if file_hash not in duplicate_files:
                        duplicate_files[file_hash] = [file_hashes[file_hash]]
                    duplicate_files[file_hash].append(image_file)
                    print(f"å‘ç°é‡å¤æ–‡ä»¶: {image_file.name}")
                else:
                    file_hashes[file_hash] = image_file
        
        self.duplicate_files = duplicate_files
        
        # ç¬¬äºŒæ­¥ï¼šå¹¶å‘å¤„ç†éé‡å¤æ–‡ä»¶
        print("å¼€å§‹å¹¶å‘OCRè¯†åˆ«...")
        non_duplicate_files = []
        for image_file in image_files:
            file_hash = self.get_file_hash(image_file)
            if file_hash not in duplicate_files:
                non_duplicate_files.append(image_file)
        
        print(f"æ€»æ–‡ä»¶æ•°: {len(image_files)} ä¸ª")
        print(f"éœ€è¦å¤„ç†çš„æ–‡ä»¶: {len(non_duplicate_files)} ä¸ª")
        print(f"é‡å¤æ–‡ä»¶ç»„: {len(duplicate_files)} ç»„")
        print(f"é‡å¤æ–‡ä»¶æ€»æ•°: {sum(len(files) for files in duplicate_files.values())} ä¸ª")
        
        # è¯¦ç»†æ˜¾ç¤ºé‡å¤æ–‡ä»¶ä¿¡æ¯
        if duplicate_files:
            print("é‡å¤æ–‡ä»¶è¯¦æƒ…:")
            for hash_val, files in duplicate_files.items():
                print(f"  å“ˆå¸Œ {hash_val[:8]}...: {[f.name for f in files]}")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {executor.submit(self.process_single_image, img): img for img in non_duplicate_files}
            
            # æ”¶é›†ç»“æœ
            processed_count = 0
            cached_count = 0
            for future in concurrent.futures.as_completed(future_to_file):
                processed_count += 1
                result = future.result()
                
                if result['type'] == 'success':
                    results.append({
                        'file': result['file'],
                        'order_number': result['order_number'],
                        'amount': result['amount'],
                        'folder': result['folder'],
                        'relative_path': result['relative_path'],
                    })
                elif result['type'] == 'cached':
                    cached_count += 1
                    results.append({
                        'file': result['file'],
                        'order_number': result['order_number'],
                        'amount': result['amount'],
                        'folder': result['folder'],
                        'relative_path': result['relative_path'],
                    })
                elif result['type'] == 'failed':
                    failed_files.append(result['file'])
                elif result['type'] == 'error':
                    failed_files.append(result['file'])
                
                # æ˜¾ç¤ºè¿›åº¦
                if processed_count % 10 == 0 or processed_count == len(non_duplicate_files):
                    print(f"è¿›åº¦: {processed_count}/{len(non_duplicate_files)} (ç¼“å­˜: {cached_count})")
        
        # ä¿å­˜ç¼“å­˜
        self.save_cache()
        
        # å¤„ç†é‡å¤æ–‡ä»¶ä¿¡æ¯
        duplicate_info = []
        for file_hash, files in duplicate_files.items():
            duplicate_info.append({
                'hash': file_hash,
                'files': [str(f.relative_to(self.source_folder)) if f.parent != self.source_folder else f.name for f in files],
                'count': len(files)
            })
        
        print(f"å¤„ç†å®Œæˆ: æˆåŠŸ {len(results)}, å¤±è´¥ {len(failed_files)}, ç¼“å­˜ {cached_count}")
        
        return results, failed_files, duplicate_info
    
    def deduplicate_by_order(self, results):
        """æ ¹æ®è®¢å•å·å»é‡"""
        unique_orders = {}
        duplicates = defaultdict(list)
        
        for result in results:
            order_num = result['order_number']
            if order_num not in unique_orders:
                unique_orders[order_num] = result
            else:
                duplicates[order_num].append(result)
        
        return unique_orders, duplicates
    
    def process(self):
        """ä¸»å¤„ç†æµç¨‹"""
        print(f"å¼€å§‹å¤„ç†æ–‡ä»¶å¤¹: {self.source_folder}")
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡
        image_files = self.find_all_images()
        total_files = len(image_files)
        
        print(f"æ‰¾åˆ° {total_files} å¼ å›¾ç‰‡")
        
        if total_files == 0:
            return {
                'total_files': 0,
                'success_count': 0,
                'failed_count': 0,
                'error': 'æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶'
            }
        
        # å¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼ˆåŒ…å«é‡å¤æ£€æµ‹ï¼‰
        results, failed_files, duplicate_info = self.process_images(image_files)
        
        success_count = len(results)
        failed_count = len(failed_files)
        
        # å»é‡
        unique_orders = {}
        duplicates = {}
        total_amount = 0
        
        if results:
            unique_orders, duplicates = self.deduplicate_by_order(results)
            
            # è®¡ç®—æ€»é‡‘é¢
            for order_num, result in unique_orders.items():
                total_amount += result['amount']
            
            # å¤åˆ¶å»é‡åçš„æ–‡ä»¶ï¼Œä¿æŒæ–‡ä»¶å¤¹ç»“æ„
            for i, (order_num, result) in enumerate(sorted(unique_orders.items(), key=lambda x: x[1]['amount'], reverse=True), 1):
                source_file = result['file']
                folder_path = result.get('folder', 'æ ¹ç›®å½•')
                relative_path = result.get('relative_path', source_file.name)
                
                # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹
                dest_folder = self.deduped_folder
                if folder_path != 'æ ¹ç›®å½•':
                    dest_folder = dest_folder / folder_path
                    dest_folder.mkdir(parents=True, exist_ok=True)
                
                # ç”Ÿæˆæ–°æ–‡ä»¶å
                new_filename = f"{i:03d}_Â¥{result['amount']:.2f}_{source_file.name}"
                dest_file = dest_folder / new_filename
                
                try:
                    shutil.copy2(source_file, dest_file)
                except Exception as e:
                    print(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {source_file.name} - {e}")
        
        # è®¡ç®—é‡å¤æ–‡ä»¶ç»Ÿè®¡
        total_duplicate_files = sum(info['count'] for info in duplicate_info)
        
        # å‡†å¤‡è¿”å›ç»“æœ
        result_data = {
            'total_files': total_files,
            'success_count': success_count,
            'failed_count': failed_count,
            'unique_orders': len(unique_orders),
            'duplicate_orders': len(duplicates),
            'duplicate_images': len(duplicate_info),
            'total_duplicate_files': total_duplicate_files,
            'total_amount': round(total_amount, 2),
            'orders': [],
            'duplicates': [],
            'duplicate_images_list': duplicate_info,
            'failed_files': [f.name for f in failed_files]
        }
        
        # è¯¦ç»†è®¢å•åˆ—è¡¨
        for i, (order_num, result) in enumerate(sorted(unique_orders.items(), key=lambda x: x[1]['amount'], reverse=True), 1):
            result_data['orders'].append({
                'index': i,
                'order_number': order_num,
                'amount': result['amount'],
                'filename': result['file'].name,
                'folder': result['folder'],
                'relative_path': result.get('relative_path', result['file'].name)
            })
        
        # é‡å¤è®¢å•åˆ—è¡¨
        for order_num, dup_list in duplicates.items():
            original = unique_orders[order_num]
            result_data['duplicates'].append({
                'order_number': order_num,
                'amount': original['amount'],
                'original_file': original['file'].name,
                'duplicate_files': [dup['file'].name for dup in dup_list],
                'duplicate_count': len(dup_list)
            })
        
        # é‡å¤å›¾ç‰‡åˆ—è¡¨å·²ç»åœ¨duplicate_infoä¸­å¤„ç†ï¼Œä¸éœ€è¦é¢å¤–å¤„ç†
        
        print(f"å¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}, å”¯ä¸€è®¢å• {len(unique_orders)}")
        
        return result_data

